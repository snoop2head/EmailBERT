CFG:
  model_checkpoint: roberta-large
  data_path: snoop2head/enron_aeslc_emails # one of snoop2head/common_crawl, c4, openwebtext
  chunk_size: 512
  masking_probability: 0.15
  whole_word_masking_probability: 0.2
  train_size: 482133
  test_size: 53570
  batch_size: 14
  seed: 42
  learning_rate: 0.00002
  weight_decay: 0.01
  warm_up_ratio: 0.1
  num_train_epochs: 10
  early_stop: 3 # 1 and above for early stop activation. -1 for no early stop
  fp16: true
  gradient_checkpointing: false
  logging_steps: 1000
  save_total_limit: 5
